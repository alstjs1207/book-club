# TIL (2023.05.17)

## DAY 3

오늘 읽은 범위: 시작 - 3장) OS 캐시와 분산

---

```text
😉 책에서 기억하고 싶은 내용을 써보세요.
```

## OS의 캐시 구조

- OS는 메모리를 이용해서 디스크 액세스를 줄인다. -> 그 원리가 OS 캐시

### Linux(x86)의 페이징 구조를 예로

- 논리적인 선형 어드레스 -> 페이징 구조 -> 물리적인 물리 어드레스 : 가상 메모리 구조의 기반

### 가상 메모리 구조

- 가상 메모리구조가 존재하는 가장 큰 이유는 물리적인 하드웨어를 OS에서 추상화하기 위해서다.
- 프로세스에서 메모리를 요청 -> OS가 메모리에서 비어있는 곳을 찾아서 반환
  - 개별 프로세스에서는 메모리의 어느 부분을 사용하는지 관여하지 않는다.
  - 0X000과 같이 반드시 메모리의 특정 번지부터 시작한다고 정해져 있는 편이 프로세스에게는 다루기 쉽다.
- OS는 프로세스에서 메모리를 요청받으면 페이지(블록)를 1개 이상, 필요한 만큼 페이지를 확보해서 프로세스에게 넘기는 작업을 수행
  페이지: OS가 물리 메모리를 확보/관리하는 단위

### Linux의 페이지 캐시 원리

- 디스크의 내용을 일단 메모리에 읽어들인다.(프로세스는 디스크에 직접 액세스할 수 없기 때문)
  -> OS는 그 메모리 주소를 프로세스에 알려준다.
  -> 프로세스가 해당 메모리에 엑세스한다.
  -> 전부 처리하고 더 이상 불필요하게 됐어도 해제하지 않고 남겨둔다.
  -> 다른 프로세스가 남겨두었던 페이지를 사용 (페이징 캐시)
- 페이지 캐시의 친숙한 효과
  - 예외의 경우를 제외하고 모든 I/O에 투과적으로 작용

### VFS (Virtual File System, 가상 파일시스템)

- 파일시스템 하위에 디바이스 드라이버가 있으며, 이 디바이스 드라이버가 실제로 하드디스크 등을 조작한다.
- 파일시스템 위에는 VFS라는 추상화 레이어가 있다.

### Linux는 페이지 단위로 디스크를 캐싱한다.

- 페이지: 가상 메모리의 최소단위
- OS는 읽어낸 블록 단위만으로 캐싱할 수 있는 범위가 정해진다.
- 만약 메모리 여유분보다 큰 파일을 전부 읽게 되면 어떻게 될까?
  -> 구조상으로는 LRU(Least Recently Used), 가장 오래된 것을 파기하고 가장 새로운 것을 남겨놓는 형태로 진행

### 메모리가 비어 있으면 캐싱

- Linux는 비어 있는 메모리 공간에 걔속해서 디스크 내용을 캐싱해간다.

### 메모리를 늘려서 I/O 부하 줄이기

- 메모리를 늘리면 -> 캐시 용량이 늘어나고 -> 많은 데이터를 캐싱 -> 디스크 읽는 획수가 줄어듦

## I/O 부하를 줄이는 방법

### 캐시를 전제로 한 I/O 줄이는 방법

- 첫번째. 데이터 규모에 비해 물리 메모리가 크면 전부 캐싱할 수 있다.
  - 경제적인 비용과의 밸런스를 고려
- 복수 서버로 확장시키기 - 캐시로 해결될 수 없는 규모일 경우

### 단순히 대수만 늘려서는 확장성을 확보할 수 없다

- 단순히 대수만 늘리면 캐싱 할 수 없는 비율은 변함없기 때문에 다시 병목이 된다.

## 국소성을 살리는 분산

### 국소성을 고려한 분산이란?

- 데이터에 대한 액세스 패턴을 고려해서 분산시키는 것을 국소성을 고려한 분산이라고 한다.
- 액세스가 되는 유형을 분리해서 DB 서버로의 접근 요청을 분배한다. (대다수의 접근 / 개인의 접근)
- 캐싱할 수 없는 부분이 사라진다. -> 메모리는 디스크보다 빠르므로 그만큼 덕을 본다.

### 파티셔닝

- 한대였던 DB 서버를 여러 대의 서버로 분할하는 방법
- 간단한 방법 : 테이블 단위 분할
- 테이블 단위로 분할했으면 애플리케이션을 변경할 필요가 있음

### 요청 패턴을 '섬'으로 분할

- 용도별로 시스템을 섬으로 나누는 방법
- 책에서는 일반적인 요청, 봇/feed, 이미지 api 등 으로 분리

### 페이지 캐시를 고려한 운용의 기본 규칙

- OS 기동 직후에 서버를 투입하지 않는다는 것.
  - OS 기동 직후 자주 사용하는 DB의 파일을 한 번 cat해준다. -> 전부 메모리에 올림 -> 로드밸런서 편입
- 성능평가나 부하시험은 캐시가 최적화된 후에 실시

```text
🤔 오늘 익은 소감은? 떠오르는 생각을 가볍게 적어보세요
```

- 가상 메모리 구조에 대해서 이미지와 같이 잘 설명하고 있어서 이해하기가 쉬웠지만, 살짝 어려운 부분도 있었다.
- 현재 우리는 DB 레플리카를 만들어 main, 레플리카로 분산시킨 후 레플리카에게만 read를 하게 하였다. 이것도 국소성을 고려한 분산일까? 생각해 봤지만 책을 읽어보면 아닌 것 같다.
  책에서처럼 파티셔닝 후 애플리케이션에서 분리하여 처리하는 것도 좋은 방법일 수 있다 생각이 든다. 액세스 패턴도 처음보았지만 적용해 보면 좋겠다라는 생각이 든다.
  예를 들어 시청 기록은 굉장히 많은 데이터가 생성되므로 분리하고 관리자가 관리하는 테이블과 사용자에 의해 생성되는 테이블을 분리해서 관리하는 것도 좋은 방법이라 생각된다.

```text
궁금한 내용이 있거나, 잘 이해되지 않는 내용이 있다면 적어보세요.
```

- 기동 직후 DB 파일을 한 번 cat 해준다는 것이 무엇인지 모르겠다.

## TIL (2023.05.05)

### DAY 2

오늘 읽은 범위: 시작 - 2장) 대규모 데이터 처리 입문

---

```
😉 책에서 기억하고 싶은 내용을 써보세요.
```

### 하테나 북마크의 데이터 규모

- 특정 테이블의 건수: 3억5천건
- 대규모 데이터로의 쿼리
  - 아무 생각 없이 던진 쿼리에 대해 응답하지 않는다.

### 대규모 데이터 처리의 어려운 점

- 메모리 내에서 계산할 수 없다. 계산 할 수 없다면 디스크에 있는 데이터를 검색할 필요가 있다.
- 하지만 디스크는 느리므로 I/O에 시간이 걸린다.
- 메모리와 디스크의 속도차 : 10^5 ~ 10^6 정도 차이(10만~100만배)
- 디스크는 왜 늦을까?
  - 메모리와 달리 회전 등의 물리적인 동작을 수반하고, 이 물리적인 구조가 탐색속도에 영향
  - 메모리는 1회 탐색 시 마이크로초(10^-6)면 되지만, 디스크는 수 밀리초(10^-3)가 걸린다.
  - 물론 OS는 연속된 데이터를 같은 위치에 쌓는다.(그래도 속도차는 피할 수 없다.)
- 전송 속도의 차
  - 메모리와 CPU는 상당히 빠른 버스로 연결되어 있음

### 규모조정의 요소

- 규모조정(scaling)과 확장성(scalability)
- 스케일 아웃전략이 더 나은 이유는 웹 서비스에 적합하고 비용이 저렴, 시스템 구성에 유연성이 있음
- 웹 애플리케이션과 부하의 관계
  - 프록시 -> AP서버 -> DB -> AP서버 -> 클라이언트
  - AP 서버는 CPU 부하만 걸리므로 분산이 간단 -> 로드밸런서로 분산
  - DB의 I/O 부하에는 문제가 있다. -> 데이터 동기화 문제
- DB 확장성 확보의 어려움

  - 시스템을 이용하면서 무겁게 느껴진다고 해서 '서버를 늘리지'라고 생각하는 것은 위험하다.

- Column
  - Load Average : 처리를 실행하려고 해도 실행할 수 없어서 대기하고 있는 프로세스의 수
    - CPU의 실행권한이 부여되기를 기다리고 있는 프로세스
    - 디스크 I/O가 완료하기를 기다리고 있는 프로세스

### 대규모 데이터를 다루기 위한 기초지식

- 프로그램을 작성할 때의 요령

  - 어떻게 하면 메모리에서 처리를 마칠 수 있을까?
    - 디스크 seek 횟수 최소화하기
    - 국소성을 활용한 분산 실현
  - 데이터량 증가에 강한 알고리즘, 데이터 구조
    - 선형검색 -> 이분검색
    - O(n) -> O(log n)
  - 데이터 압축, 정보검색 기술
    - 특정 용도에 특화된 검색 엔진 사용

- 대규모 데이터를 다루기 전 3대 전제지식
  - OS 캐시 (chapter 03)
  - 분산을 고려한 RDBMS 운용 (chapter 04)
  - 알고리즘과 데이터 구조 (chapter 05)

```
🤔 오늘 익은 소감은? 떠오르는 생각을 가볍게 적어보세요
```

- 대규모 데이터에서 중요한 3대 전제지식을 확인했다. 아직 해당 챕터를 읽진 않았지만 가장 적용해 볼 수 있는 것은 알고리즘 최적화일 듯 하다.
  하지만 앞서 말씀 주셨던 것 처럼 이른 최적화는 좋은 방침이 아니기에 어떤 순간에 적용해야 하는지 궁금하다.
- 메모리와 디스크의 차이를 이미지를 통해 잘 설명해준 것 같아서 이해하기가 편했다.
- 아직은 대규모 데이터의 전반적인 큰그림을 설명하는 챕터인 것 같다.

```
궁금한 내용이 있거나, 잘 이해되지 않는 내용이 있다면 적어보세요.
```
